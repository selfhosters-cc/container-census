package vulnerability

import (
	"fmt"
	"testing"
	"time"
)

func TestScheduler_QueueScan_NewImage(t *testing.T) {
	storage := newMockStorage()
	config := DefaultConfig()
	config.SetEnabled(true)
	config.SetWorkerPoolSize(2)

	scanner := NewScanner(config, storage)
	scheduler := NewScheduler(scanner, config)
	scheduler.Start()
	defer scheduler.Stop()

	// Queue a new image (should be queued)
	err := scheduler.QueueScan("sha256:new-image", "nginx:latest", 0)
	if err != nil {
		t.Errorf("Failed to queue new image: %v", err)
	}

	// Give workers time to process
	time.Sleep(100 * time.Millisecond)

	// Check queue status
	status := scheduler.GetQueueStatus()
	if status.CompletedToday == 0 && status.FailedToday == 0 {
		// Either completed or failed (failed is expected without Trivy installed)
		t.Log("Scan queued successfully (worker picked it up)")
	}
}

func TestScheduler_QueueScan_AlreadyScanned(t *testing.T) {
	storage := newMockStorage()
	config := DefaultConfig()
	config.SetEnabled(true)
	config.SetCacheTTL(24)

	scanner := NewScanner(config, storage)
	scheduler := NewScheduler(scanner, config)

	// Pre-populate with a fresh scan
	scan := &VulnerabilityScan{
		ImageID:   "sha256:cached-image",
		ImageName: "nginx:latest",
		ScannedAt: time.Now(),
		Success:   true,
	}
	err := storage.SaveVulnerabilityScan(scan, []Vulnerability{})
	if err != nil {
		t.Fatalf("Failed to save scan: %v", err)
	}

	scheduler.Start()
	defer scheduler.Stop()

	// Queue the same image (should be silently skipped)
	err = scheduler.QueueScan("sha256:cached-image", "nginx:latest", 0)
	if err != nil {
		t.Errorf("Failed to queue cached image: %v", err)
	}

	// Check queue status - should not have queued anything
	status := scheduler.GetQueueStatus()
	if status.Queued > 0 {
		t.Error("Expected queue to be empty for cached image")
	}
}

func TestScheduler_QueueScan_DisabledScanning(t *testing.T) {
	storage := newMockStorage()
	config := DefaultConfig()
	config.SetEnabled(false) // Scanning disabled

	scanner := NewScanner(config, storage)
	scheduler := NewScheduler(scanner, config)
	scheduler.Start()
	defer scheduler.Stop()

	// Queue a scan when scanning is disabled (should be silently ignored)
	err := scheduler.QueueScan("sha256:any-image", "nginx:latest", 0)
	if err != nil {
		t.Errorf("QueueScan should not return error when disabled: %v", err)
	}

	// Queue should be empty
	status := scheduler.GetQueueStatus()
	if status.Queued > 0 {
		t.Error("Expected queue to be empty when scanning is disabled")
	}
}

func TestScheduler_GetQueueStatus(t *testing.T) {
	storage := newMockStorage()
	config := DefaultConfig()
	config.SetEnabled(true)
	config.SetWorkerPoolSize(3)
	// MaxQueueSize defaults to 100

	scanner := NewScanner(config, storage)
	scheduler := NewScheduler(scanner, config)
	scheduler.Start()
	defer scheduler.Stop()

	// Check initial status
	status := scheduler.GetQueueStatus()

	if status.TotalWorkers != 3 {
		t.Errorf("Expected 3 workers, got %d", status.TotalWorkers)
	}

	if status.Queued != 0 {
		t.Errorf("Expected 0 queued items initially, got %d", status.Queued)
	}

	if status.InProgress != 0 {
		t.Errorf("Expected 0 in-progress items initially, got %d", status.InProgress)
	}

	if status.CompletedToday != 0 {
		t.Errorf("Expected 0 completed items initially, got %d", status.CompletedToday)
	}
}

func TestScheduler_RescanAll(t *testing.T) {
	storage := newMockStorage()
	config := DefaultConfig()
	config.SetEnabled(true)
	config.SetCacheTTL(24)

	scanner := NewScanner(config, storage)
	scheduler := NewScheduler(scanner, config)
	scheduler.Start()
	defer scheduler.Stop()

	// Pre-populate with fresh scans
	imageIDs := map[string]string{
		"sha256:image1": "nginx:latest",
		"sha256:image2": "redis:latest",
		"sha256:image3": "postgres:latest",
	}

	for imageID, imageName := range imageIDs {
		scan := &VulnerabilityScan{
			ImageID:   imageID,
			ImageName: imageName,
			ScannedAt: time.Now(),
			Success:   true,
		}
		err := storage.SaveVulnerabilityScan(scan, []Vulnerability{})
		if err != nil {
			t.Fatalf("Failed to save scan: %v", err)
		}
	}

	// RescanAll should invalidate cache and queue all images
	count := scheduler.RescanAll(imageIDs)

	if count != 3 {
		t.Errorf("Expected 3 images to be queued for rescan, got %d", count)
	}

	// Give workers time to process
	time.Sleep(200 * time.Millisecond)

	// Check status
	status := scheduler.GetQueueStatus()
	totalProcessed := status.CompletedToday + status.FailedToday

	if totalProcessed < 3 {
		t.Logf("Warning: Expected 3 scans to be processed, got %d (workers may still be running)", totalProcessed)
	}
}

func TestScheduler_WorkerPoolSizeChange(t *testing.T) {
	storage := newMockStorage()
	config := DefaultConfig()
	config.SetEnabled(true)
	config.SetWorkerPoolSize(2)

	scanner := NewScanner(config, storage)
	scheduler := NewScheduler(scanner, config)
	scheduler.Start()

	// Check initial worker count
	status := scheduler.GetQueueStatus()
	if status.TotalWorkers != 2 {
		t.Errorf("Expected 2 workers initially, got %d", status.TotalWorkers)
	}

	// Update worker pool size
	newConfig := DefaultConfig()
	newConfig.SetEnabled(true)
	newConfig.SetWorkerPoolSize(4)

	scheduler.UpdateConfig(newConfig)

	// Give it time to restart
	time.Sleep(100 * time.Millisecond)

	// Check new worker count
	status = scheduler.GetQueueStatus()
	if status.TotalWorkers != 4 {
		t.Errorf("Expected 4 workers after update, got %d", status.TotalWorkers)
	}

	scheduler.Stop()
}

func TestScheduler_QueueBlockingBehavior(t *testing.T) {
	storage := newMockStorage()
	config := DefaultConfig()
	config.SetEnabled(true)
	// Note: MaxQueueSize cannot be modified via setter, defaults to 100

	scanner := NewScanner(config, storage)
	scheduler := NewScheduler(scanner, config)
	scheduler.Start()
	defer scheduler.Stop()

	// Queue items without workers processing (workers are slow without real Trivy)
	// Non-blocking QueueScan should succeed even if queue fills
	for i := 0; i < 5; i++ {
		err := scheduler.QueueScan(fmt.Sprintf("sha256:image%d", i), "nginx:latest", 0)
		if err != nil {
			t.Errorf("QueueScan should not return error even when queue is full: %v", err)
		}
	}
}

func TestScheduler_PriorityOrdering(t *testing.T) {
	storage := newMockStorage()
	config := DefaultConfig()
	config.SetEnabled(true)
	config.SetWorkerPoolSize(1) // Single worker to control processing order

	scanner := NewScanner(config, storage)
	scheduler := NewScheduler(scanner, config)
	scheduler.Start()
	defer scheduler.Stop()

	// Queue scans with different priorities
	// Note: Current implementation doesn't actually prioritize, but this tests the API
	err := scheduler.QueueScan("sha256:low-priority", "nginx:latest", 0)
	if err != nil {
		t.Errorf("Failed to queue low priority: %v", err)
	}

	err = scheduler.QueueScan("sha256:high-priority", "redis:latest", 10)
	if err != nil {
		t.Errorf("Failed to queue high priority: %v", err)
	}

	// Give workers time to process
	time.Sleep(200 * time.Millisecond)

	// Both should have been attempted (order may vary)
	status := scheduler.GetQueueStatus()
	if status.CompletedToday+status.FailedToday < 2 {
		t.Logf("Warning: Expected 2 scans processed, got %d", status.CompletedToday+status.FailedToday)
	}
}

func TestScheduler_StopGracefully(t *testing.T) {
	storage := newMockStorage()
	config := DefaultConfig()
	config.SetEnabled(true)
	config.SetWorkerPoolSize(2)

	scanner := NewScanner(config, storage)
	scheduler := NewScheduler(scanner, config)
	scheduler.Start()

	// Queue some scans
	for i := 0; i < 5; i++ {
		err := scheduler.QueueScan(fmt.Sprintf("sha256:image%d", i), "nginx:latest", 0)
		if err != nil {
			t.Errorf("Failed to queue scan: %v", err)
		}
	}

	// Stop should complete within timeout
	done := make(chan bool)
	go func() {
		scheduler.Stop()
		done <- true
	}()

	select {
	case <-done:
		t.Log("Scheduler stopped gracefully")
	case <-time.After(35 * time.Second):
		t.Error("Scheduler did not stop within timeout")
	}
}

func TestScheduler_ConcurrentQueueing(t *testing.T) {
	storage := newMockStorage()
	config := DefaultConfig()
	config.SetEnabled(true)
	config.SetWorkerPoolSize(3)

	scanner := NewScanner(config, storage)
	scheduler := NewScheduler(scanner, config)
	scheduler.Start()
	defer scheduler.Stop()

	// Concurrent queueing
	done := make(chan bool)
	for i := 0; i < 10; i++ {
		go func(id int) {
			err := scheduler.QueueScan(fmt.Sprintf("sha256:image%d", id), "nginx:latest", 0)
			if err != nil {
				t.Errorf("Failed to queue scan from goroutine: %v", err)
			}
			done <- true
		}(i)
	}

	// Wait for all goroutines
	for i := 0; i < 10; i++ {
		<-done
	}

	// Give workers time to process
	time.Sleep(300 * time.Millisecond)

	// Check status (should have processed some scans)
	status := scheduler.GetQueueStatus()
	t.Logf("After concurrent queueing: Completed=%d, Failed=%d, Queued=%d, InProgress=%d",
		status.CompletedToday, status.FailedToday, status.Queued, status.InProgress)
}

func TestScheduler_DailyStatsReset(t *testing.T) {
	storage := newMockStorage()
	config := DefaultConfig()
	config.SetEnabled(true)

	scanner := NewScanner(config, storage)
	scheduler := NewScheduler(scanner, config)
	scheduler.Start()
	defer scheduler.Stop()

	// Queue and process a scan
	err := scheduler.QueueScan("sha256:test-image", "nginx:latest", 0)
	if err != nil {
		t.Errorf("Failed to queue scan: %v", err)
	}

	// Give worker time to process
	time.Sleep(200 * time.Millisecond)

	status1 := scheduler.GetQueueStatus()
	initialTotal := status1.CompletedToday + status1.FailedToday

	if initialTotal == 0 {
		t.Skip("Scan did not complete (expected in test environment without Trivy)")
	}

	// Note: Testing the daily reset would require manipulating time or waiting 24 hours
	// Instead, we verify the stats tracking is working
	t.Logf("Daily stats tracking working: Completed=%d, Failed=%d", status1.CompletedToday, status1.FailedToday)
}

func TestScheduler_QueueCapacity(t *testing.T) {
	storage := newMockStorage()
	config := DefaultConfig()
	config.SetEnabled(true)
	// MaxQueueSize defaults to 100
	config.SetWorkerPoolSize(1) // One slow worker

	scanner := NewScanner(config, storage)
	scheduler := NewScheduler(scanner, config)
	scheduler.Start()
	defer scheduler.Stop()

	// Queue many items (less than 100)
	for i := 0; i < 50; i++ {
		err := scheduler.QueueScan(fmt.Sprintf("sha256:image%d", i), "nginx:latest", 0)
		if err != nil {
			t.Errorf("Failed to queue item %d: %v", i, err)
		}
	}

	// Should have queued successfully (workers will be processing slowly)
	t.Log("Successfully queued 50 items (max queue size is 100)")
}
