package vulnerability

import (
	"context"
	"log"
	"sync"
	"sync/atomic"
	"time"
)

// Scheduler manages the vulnerability scanning queue and worker pool
type Scheduler struct {
	scanner         *Scanner
	config          *Config
	queue           chan ScanJob
	workers         []*worker
	mu              sync.RWMutex
	ctx             context.Context
	cancel          context.CancelFunc
	inProgressCount int32
	completedToday  int32
	failedToday     int32
	lastResetDate   string
}

// worker represents a single scan worker
type worker struct {
	id        int
	scheduler *Scheduler
}

// NewScheduler creates a new scan scheduler
func NewScheduler(scanner *Scanner, config *Config) *Scheduler {
	ctx, cancel := context.WithCancel(context.Background())

	s := &Scheduler{
		scanner:       scanner,
		config:        config,
		queue:         make(chan ScanJob, config.GetMaxQueueSize()),
		ctx:           ctx,
		cancel:        cancel,
		lastResetDate: time.Now().Format("2006-01-02"),
	}

	return s
}

// Start starts the worker pool
func (s *Scheduler) Start() {
	s.mu.Lock()
	defer s.mu.Unlock()

	workerCount := s.config.GetWorkerPoolSize()
	log.Printf("Starting vulnerability scanner with %d workers", workerCount)

	s.workers = make([]*worker, workerCount)
	for i := 0; i < workerCount; i++ {
		w := &worker{
			id:        i + 1,
			scheduler: s,
		}
		s.workers[i] = w
		go w.run()
	}

	// Start daily stats reset goroutine
	go s.dailyStatsReset()
}

// Stop stops the worker pool
func (s *Scheduler) Stop() {
	log.Println("Stopping vulnerability scanner...")
	s.cancel()

	s.mu.Lock()
	defer s.mu.Unlock()

	// Close the queue
	close(s.queue)

	// Wait for all workers to finish (with timeout)
	done := make(chan struct{})
	go func() {
		for atomic.LoadInt32(&s.inProgressCount) > 0 {
			time.Sleep(100 * time.Millisecond)
		}
		close(done)
	}()

	select {
	case <-done:
		log.Println("All workers stopped gracefully")
	case <-time.After(30 * time.Second):
		log.Println("Warning: Some workers did not stop within timeout")
	}
}

// QueueScan adds a scan job to the queue
func (s *Scheduler) QueueScan(imageID, imageName string, priority int) error {
	// Check if scanning is enabled
	if !s.config.GetEnabled() {
		return nil // Silently ignore if disabled
	}

	// Check if image needs scanning
	if !s.scanner.NeedsScan(imageID) {
		return nil // Already scanned recently
	}

	job := ScanJob{
		ImageID:   imageID,
		ImageName: imageName,
		Priority:  priority,
		QueuedAt:  time.Now(),
	}

	select {
	case s.queue <- job:
		return nil
	default:
		return nil // Queue is full, silently drop (could log warning)
	}
}

// QueueScanBlocking adds a scan job and waits if queue is full
func (s *Scheduler) QueueScanBlocking(imageID, imageName string, priority int) error {
	if !s.config.GetEnabled() {
		return nil
	}

	if !s.scanner.NeedsScan(imageID) {
		return nil
	}

	job := ScanJob{
		ImageID:   imageID,
		ImageName: imageName,
		Priority:  priority,
		QueuedAt:  time.Now(),
	}

	select {
	case s.queue <- job:
		return nil
	case <-s.ctx.Done():
		return s.ctx.Err()
	}
}

// GetQueueStatus returns the current queue status
func (s *Scheduler) GetQueueStatus() ScanQueueStatus {
	// Get queue items
	s.mu.RLock()
	queueItems := make([]ScanJob, 0, len(s.queue))
	for i := 0; i < len(s.queue); i++ {
		select {
		case job := <-s.queue:
			queueItems = append(queueItems, job)
			// Put it back
			s.queue <- job
		default:
		}
	}
	s.mu.RUnlock()

	return ScanQueueStatus{
		Queued:        len(s.queue),
		InProgress:    int(atomic.LoadInt32(&s.inProgressCount)),
		CompletedToday: int(atomic.LoadInt32(&s.completedToday)),
		FailedToday:   int(atomic.LoadInt32(&s.failedToday)),
		QueueItems:    queueItems,
		TotalWorkers:  s.config.GetWorkerPoolSize(),
		ActiveWorkers: int(atomic.LoadInt32(&s.inProgressCount)), // Active = currently scanning
	}
}

// worker.run processes scan jobs from the queue
func (w *worker) run() {
	log.Printf("Vulnerability scanner worker %d started", w.id)

	for {
		select {
		case job, ok := <-w.scheduler.queue:
			if !ok {
				log.Printf("Vulnerability scanner worker %d stopped", w.id)
				return
			}

			w.processJob(job)

		case <-w.scheduler.ctx.Done():
			log.Printf("Vulnerability scanner worker %d stopped", w.id)
			return
		}
	}
}

// worker.processJob processes a single scan job
func (w *worker) processJob(job ScanJob) {
	atomic.AddInt32(&w.scheduler.inProgressCount, 1)
	defer atomic.AddInt32(&w.scheduler.inProgressCount, -1)

	// Perform the scan
	_, err := w.scheduler.scanner.ScanImage(w.scheduler.ctx, job.ImageName)
	if err != nil {
		// Only log unexpected errors (not "image not available")
		if err.Error() != "image not available for scanning" {
			log.Printf("Worker %d: Scan failed for %s: %v", w.id, job.ImageName, err)
		}
		atomic.AddInt32(&w.scheduler.failedToday, 1)
	} else {
		atomic.AddInt32(&w.scheduler.completedToday, 1)
	}
}

// dailyStatsReset resets daily counters at midnight
func (s *Scheduler) dailyStatsReset() {
	ticker := time.NewTicker(1 * time.Hour)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			currentDate := time.Now().Format("2006-01-02")
			if currentDate != s.lastResetDate {
				log.Println("Resetting daily vulnerability scan statistics")
				atomic.StoreInt32(&s.completedToday, 0)
				atomic.StoreInt32(&s.failedToday, 0)
				s.lastResetDate = currentDate
			}

		case <-s.ctx.Done():
			return
		}
	}
}

// RescanAll queues all images for rescanning
func (s *Scheduler) RescanAll(imageIDs map[string]string) int {
	count := 0
	for imageID, imageName := range imageIDs {
		// Invalidate cache to force rescan
		s.scanner.InvalidateCache(imageID)

		err := s.QueueScan(imageID, imageName, 0)
		if err == nil {
			count++
		}
	}
	return count
}

// UpdateConfig updates the scheduler configuration
func (s *Scheduler) UpdateConfig(config *Config) {
	s.config = config
	s.scanner.SetConfig(config)

	// If worker pool size changed, restart workers
	s.mu.Lock()
	currentWorkerCount := len(s.workers)
	newWorkerCount := config.GetWorkerPoolSize()
	s.mu.Unlock()

	if currentWorkerCount != newWorkerCount {
		log.Printf("Worker pool size changed from %d to %d, restarting workers", currentWorkerCount, newWorkerCount)
		s.Stop()
		// Create new queue with new size
		s.queue = make(chan ScanJob, config.GetMaxQueueSize())
		s.ctx, s.cancel = context.WithCancel(context.Background())
		s.Start()
	}
}
